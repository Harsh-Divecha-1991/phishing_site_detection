{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('..\\data\\processed\\phishing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing module and initializing setup\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originaldata = setup(data = df, target = 'Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the Best Model\n",
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "model_folder = os.path.join('..', 'models')\n",
    "os.makedirs(model_folder, exist_ok=True) \n",
    "\n",
    "models = ['et', 'rf', 'lightgbm', 'dt', 'gbc']\n",
    "\n",
    "def train_model(models):\n",
    "    for model in models:\n",
    "        print(f\"Model : {model}\")\n",
    "        # train rf model using 25 fold CV\n",
    "        classifier_model = create_model(model, fold = 25)\n",
    "        plot_model(classifier_model, plot = 'auc')\n",
    "        plot_model(classifier_model, plot = 'pr')\n",
    "        plot_model(classifier_model, plot = 'feature')\n",
    "        plot_model(classifier_model, plot = 'confusion_matrix')\n",
    "\n",
    "        # save_model(classifier_model, os.path.join('..'. 'models', model+'_model'))\n",
    "        with open(os.path.join('..', 'models', model+'_model.pkl'), 'wb') as files:\n",
    "            pickle.dump(classifier_model, files)\n",
    "        \n",
    "        print('_'*50)\n",
    "\n",
    "train_model(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def load_model(pkl_file_path):\n",
    "    with open(pkl_file_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "        # model = joblib.load(pkl_file_path)\n",
    "    return model\n",
    "\n",
    "def predict_with_model(model, input_data, class_names):\n",
    "    # Make a prediction\n",
    "    # predicted_output = model.predict([input_data])\n",
    "    predicted_proba = model.predict_proba([input_data])[0]\n",
    "    predicted_class_index = np.argmax(predicted_proba)\n",
    "    predicted_class_name = class_names[predicted_class_index]\n",
    "    predicted_class_probability = predicted_proba[predicted_class_index]\n",
    "\n",
    "    return {\n",
    "        \"class_name\": predicted_class_name,\n",
    "        \"probability\": predicted_class_probability\n",
    "    }\n",
    "\n",
    "def predict_with_voting(class_names, probabilities):\n",
    "    # Create a Counter object to count occurrences of each element\n",
    "    element_counter = Counter(class_names)\n",
    "    \n",
    "    # Find the element with the maximum count\n",
    "    most_common_element, count = element_counter.most_common(1)[0]\n",
    "    \n",
    "    # Find average of probabilities\n",
    "    avg_probability = np.mean(probabilities)\n",
    "    \n",
    "    return most_common_element, avg_probability\n",
    "\n",
    "def multimodel_voting(input_data, op_val=None): \n",
    "    model_class_names, model_probabilities = [], []\n",
    "    \n",
    "    for md in glob.glob(os.path.join('..', 'models', '*')):\n",
    "\n",
    "        pkl_file_path = md # 'path_to_your_model.pkl'\n",
    "        class_names = [-1, 1] # ['unsafe', 'safe'] # [-1, 1] # Update with your actual class names\n",
    "\n",
    "        model = load_model(pkl_file_path)\n",
    "        result = predict_with_model(model, input_data, class_names)\n",
    "        model_class_names.append(result['class_name'])\n",
    "        model_probabilities.append(result['probability'])\n",
    "\n",
    "        print(result, ' || ',  op_val)\n",
    "        print('__'*30)\n",
    "\n",
    "    result_class, result_probability = predict_with_voting(model_class_names, model_probabilities)\n",
    "    print(result_class, round(result_probability*100, 2))\n",
    "    \n",
    "    return result_class, round(result_probability*100, 2)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    df = pd.read_csv('phishing.csv')\n",
    "    input_df_copy = df.copy().drop('Result', axis = 1)\n",
    "    input_df = input_df_copy.sample(n=10)\n",
    "    input_df = input_df.reset_index(drop=True)\n",
    "    # display(input_df)\n",
    "    \n",
    "    result_op, prob_op = [], []\n",
    "    for index in range(len(input_df)):\n",
    "        res, prob = multimodel_voting(input_df.iloc[index, :], op_val=None)\n",
    "        result_op.append(res) \n",
    "        prob_op.append(prob)\n",
    "        print('\\n')\n",
    "    \n",
    "    input_df['prediction'] = result_op\n",
    "    input_df['probability'] = prob_op\n",
    "    display(input_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
